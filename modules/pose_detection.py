import streamlit as st
import tempfile
import os
import cv2
import mediapipe as mp
import numpy as np
from collections import deque
import csv
import matplotlib.pyplot as plt
import pandas as pd
import time
import subprocess
import platform
import logging

# æŠ‘åˆ¶ TensorFlow å’Œ MediaPipe çš„æ—¥èªŒ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('mediapipe').setLevel(logging.ERROR)


def calculate_angle(a, b, c):
    """
    è¨ˆç®—ä¸‰é»æ‰€å½¢æˆçš„å¤¾è§’ï¼Œb ç‚ºä¸­å¿ƒé»
    a, b, c: (x, y)
    """
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba = a - b
    bc = c - b
    denom = (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)
    if denom == 0:
        return np.nan
    cosine = np.dot(ba, bc) / denom
    return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))


def calculate_trunk_lean(shoulder, hip):
    """
    è»€å¹¹å‰å‚¾è§’ï¼šHip -> Shoulder èˆ‡ã€Œå‚ç›´å‘ä¸Šã€çš„å¤¾è§’
    å½±åƒåº§æ¨™ y è»¸å‘ä¸‹ç‚ºæ­£ï¼Œæ‰€ä»¥å‚ç›´å‘ä¸Šæ˜¯ (0, -1)
    """
    shoulder = np.array(shoulder)
    hip = np.array(hip)
    v = shoulder - hip           # hip -> shoulder
    vertical = np.array([0, -1.0])
    denom = (np.linalg.norm(v) * np.linalg.norm(vertical) + 1e-8)
    if denom == 0:
        return np.nan
    cosine = np.dot(v, vertical) / denom
    angle = np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))
    return angle


def record_from_webcam(output_video_path):
    """
    å¾æœ¬åœ°æ”åƒé ­éŒ„åˆ¶è¦–é »ï¼Œå³æ™‚é¡¯ç¤ºç¯€é»
    è¿”å›: (éŒ„åˆ¶æˆåŠŸèˆ‡å¦, éŒ„åˆ¶æ™‚é•·ç§’æ•¸)
    """
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    pose_style = mp.solutions.drawing_styles.get_default_pose_landmarks_style()
    connections = mp_pose.POSE_CONNECTIONS

    # æ‰“é–‹æœ¬åœ°æ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("âŒ ç„¡æ³•é–‹å•Ÿæ”åƒé ­ï¼Œè«‹æª¢æŸ¥æ”åƒé ­æ˜¯å¦å·²é€£æ¥")
        return False, 0

    # è¨­ç½®æ”åƒé ­åˆ†è¾¨ç‡
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    input_fps = cap.get(cv2.CAP_PROP_FPS)
    if input_fps <= 0 or np.isnan(input_fps):
        input_fps = 30.0

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # è¨­å®šå½±ç‰‡è¼¸å‡º
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, input_fps, (width, height))

    st.info("ğŸ“¹ æ”åƒé ­å·²å•Ÿå‹•ï¼")
    frame_placeholder = st.empty()
    timer_placeholder = st.empty()
    frame_count = 0
    start_time = time.time()

    try:
        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # é¡åƒç¿»è½‰ä¾¿æ–¼è‡ªæ‹
                frame = cv2.flip(frame, 1)
                
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb)

                if results.pose_landmarks:
                    # ç¹ªè£½éª¨æ¶å’Œç¯€é»
                    mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, connections,
                        landmark_drawing_spec=pose_style
                    )

                # æ·»åŠ ç‹€æ…‹æ–‡å­—
                cv2.putText(
                    frame, f"Recording... Frame: {frame_count}", (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2
                )

                # å¯«å…¥è¼¸å‡ºå½±ç‰‡
                out.write(frame)

                # è½‰æ›ç‚º RGB ä»¥åœ¨ Streamlit ä¸­é¡¯ç¤º
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(frame_rgb, width='stretch')

                # æ›´æ–°è¨ˆæ™‚å™¨
                elapsed_time = time.time() - start_time
                timer_placeholder.metric("â±ï¸ éŒ„è£½æ™‚é•·", f"{elapsed_time:.1f} ç§’")

                # æª¢æŸ¥åœæ­¢æ¨™èªŒ
                if st.session_state.get('stop_recording', False):
                    break

                frame_count += 1

    finally:
        cap.release()
        out.release()
        cv2.destroyAllWindows()

    elapsed_time = time.time() - start_time
    return True, elapsed_time


def analyze_video_pose(video_path):
    """
    åˆ†æå·²éŒ„åˆ¶çš„è¦–é »ä¸­çš„å§¿å‹¢ï¼Œè¿”å›åˆ†ææ•¸æ“š
    """
    mp_pose = mp.solutions.pose
    smooth_buffer_size = 5
    elbow_R_buffer = deque(maxlen=smooth_buffer_size)
    wrist_R_buffer = deque(maxlen=smooth_buffer_size)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("ç„¡æ³•é–‹å•Ÿå½±ç‰‡")

    # å–å¾—å½±ç‰‡è³‡è¨Š
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    input_fps = cap.get(cv2.CAP_PROP_FPS)
    if input_fps <= 0 or np.isnan(input_fps):
        input_fps = 30.0

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    data_rows = []
    frame_idx = 0

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb)

                if results.pose_landmarks:
                    h, w, _ = frame.shape
                    lm = results.pose_landmarks.landmark

                    def get_xy(name):
                        p = lm[mp_pose.PoseLandmark[name].value]
                        return np.array([p.x * w, p.y * h])

                    # å³å´é—œç¯€åº§æ¨™
                    shoulder_R = get_xy("RIGHT_SHOULDER")
                    elbow_R = get_xy("RIGHT_ELBOW")
                    wrist_R = get_xy("RIGHT_WRIST")
                    hip_R = get_xy("RIGHT_HIP")
                    knee_R = get_xy("RIGHT_KNEE")
                    ankle_R = get_xy("RIGHT_ANKLE")

                    # å·¦å´é—œç¯€åº§æ¨™
                    shoulder_L = get_xy("LEFT_SHOULDER")
                    hip_L = get_xy("LEFT_HIP")
                    knee_L = get_xy("LEFT_KNEE")
                    ankle_L = get_xy("LEFT_ANKLE")

                    # å¹³æ»‘åŒ–å³æ‰‹ç¯€é»
                    elbow_R_buffer.append(elbow_R)
                    wrist_R_buffer.append(wrist_R)

                    if len(elbow_R_buffer) == smooth_buffer_size:
                        elbow_R = np.mean(elbow_R_buffer, axis=0)
                        wrist_R = np.mean(wrist_R_buffer, axis=0)

                    # è§’åº¦è¨ˆç®—
                    right_elbow_angle = calculate_angle(shoulder_R, elbow_R, wrist_R)
                    right_shoulder_angle = calculate_angle(elbow_R, shoulder_R, hip_R)
                    right_hip_angle = calculate_angle(shoulder_R, hip_R, knee_R)
                    right_knee_angle = calculate_angle(hip_R, knee_R, ankle_R)

                    left_hip_angle = calculate_angle(shoulder_L, hip_L, knee_L)
                    left_knee_angle = calculate_angle(hip_L, knee_L, ankle_L)

                    # è»€å¹¹å‰å‚¾è§’
                    mid_shoulder = (
                        (shoulder_R[0] + shoulder_L[0]) / 2,
                        (shoulder_R[1] + shoulder_L[1]) / 2
                    )
                    mid_hip = (
                        (hip_R[0] + hip_L[0]) / 2,
                        (hip_R[1] + hip_L[1]) / 2
                    )
                    trunk_lean_deg = calculate_trunk_lean(mid_shoulder, mid_hip)

                    # è¨˜éŒ„æ•¸æ“š
                    time_sec = frame_idx / input_fps
                    data_rows.append({
                        "frame": frame_idx,
                        "time": time_sec,
                        "right_elbow_angle": right_elbow_angle,
                        "right_shoulder_angle": right_shoulder_angle,
                        "right_hip_angle": right_hip_angle,
                        "right_knee_angle": right_knee_angle,
                        "left_hip_angle": left_hip_angle,
                        "left_knee_angle": left_knee_angle,
                        "trunk_lean_deg": trunk_lean_deg,
                        "right_ankle_x": float(ankle_R[0]),
                        "right_ankle_y": float(ankle_R[1]),
                        "left_ankle_x": float(ankle_L[0]),
                        "left_ankle_y": float(ankle_L[1]),
                    })

                # æ›´æ–°é€²åº¦æ¢
                if total_frames > 0:
                    progress = min(frame_idx / total_frames, 1.0)
                    progress_bar.progress(progress)
                    status_text.text(f"åˆ†æä¸­... {frame_idx}/{total_frames} å¹€")

                frame_idx += 1

    finally:
        cap.release()
        progress_bar.empty()
        status_text.empty()

    return data_rows, input_fps, width, height


def generate_pose_analysis_plots(data_rows):
    """
    ç”Ÿæˆå§¿å‹¢åˆ†æåœ–è¡¨
    """
    if len(data_rows) == 0:
        return None, None, None, None, None

    times = [row["time"] for row in data_rows]

    # 1. å³è†è§’åº¦éš¨æ™‚é–“è®ŠåŒ–
    right_knee_angles = [row["right_knee_angle"] for row in data_rows]
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    ax1.plot(times, right_knee_angles, linewidth=2, color='#1f77b4')
    ax1.set_xlabel("Time (s)", fontsize=12)
    ax1.set_ylabel("Right Knee Angle (deg)", fontsize=12)
    ax1.set_title("Right Knee Angle over Time", fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    plt.tight_layout()

    # 2. å·¦å³è†è§’åº¦æ¯”è¼ƒ
    left_knee_angles = [row["left_knee_angle"] for row in data_rows]
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    ax2.plot(times, right_knee_angles, label="Right Knee", linewidth=2, color='#ff7f0e')
    ax2.plot(times, left_knee_angles, label="Left Knee", linewidth=2, color='#2ca02c')
    ax2.set_xlabel("Time (s)", fontsize=12)
    ax2.set_ylabel("Knee Angle (deg)", fontsize=12)
    ax2.set_title("Left vs Right Knee Angle over Time", fontsize=14, fontweight='bold')
    ax2.legend(fontsize=11)
    ax2.grid(True, alpha=0.3)
    plt.tight_layout()

    # 3. è»€å¹¹å‰å‚¾è§’åº¦
    trunk_lean = [row["trunk_lean_deg"] for row in data_rows]
    fig3, ax3 = plt.subplots(figsize=(10, 6))
    ax3.plot(times, trunk_lean, linewidth=2, color='#d62728')
    ax3.set_xlabel("Time (s)", fontsize=12)
    ax3.set_ylabel("Trunk Lean (deg)", fontsize=12)
    ax3.set_title("Trunk Lean Angle over Time", fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    plt.tight_layout()

    # 4. å³è…³è¸å‚ç›´ä½ç§»
    right_ankle_y = [row["right_ankle_y"] for row in data_rows]
    fig4, ax4 = plt.subplots(figsize=(10, 6))
    ax4.plot(times, right_ankle_y, linewidth=2, color='#9467bd')
    ax4.set_xlabel("Time (s)", fontsize=12)
    ax4.set_ylabel("Right Ankle Y (pixel)", fontsize=12)
    ax4.set_title("Right Ankle Vertical Trajectory", fontsize=14, fontweight='bold')
    ax4.invert_yaxis()
    ax4.grid(True, alpha=0.3)
    plt.tight_layout()

    # 5. å³è…³è¸åœ¨ç•«é¢ä¸­çš„ 2D è·¯å¾‘
    right_ankle_x = [row["right_ankle_x"] for row in data_rows]
    fig5, ax5 = plt.subplots(figsize=(10, 6))
    ax5.plot(right_ankle_x, right_ankle_y, linewidth=2, color='#8c564b')
    ax5.set_xlabel("Right Ankle X (pixel)", fontsize=12)
    ax5.set_ylabel("Right Ankle Y (pixel)", fontsize=12)
    ax5.set_title("Right Ankle 2D Trajectory", fontsize=14, fontweight='bold')
    ax5.invert_yaxis()
    ax5.grid(True, alpha=0.3)
    plt.tight_layout()

    return fig1, fig2, fig3, fig4, fig5


def display_analysis_results(data_rows):
    """
    é¡¯ç¤ºå§¿å‹¢åˆ†æçµæœï¼ŒåŒ…æ‹¬åœ–è¡¨ã€çµ±è¨ˆå’Œæ•¸æ“šä¸‹è¼‰
    """
    if len(data_rows) == 0:
        st.warning("æ²’æœ‰åˆ†ææ•¸æ“šå¯é¡¯ç¤º")
        return

    # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("ç¸½å¹€æ•¸", f"{len(data_rows)}", help="å·²åˆ†æçš„å½±ç‰‡å¹€æ•¸")
    with col2:
        duration = data_rows[-1]["time"] if data_rows else 0
        st.metric("åˆ†ææ™‚é–“", f"{duration:.1f}ç§’", help="åˆ†æçš„æŒçºŒæ™‚é–“")
    with col3:
        fps = len(data_rows) / duration if duration > 0 else 0
        st.metric("å¹³å‡ FPS", f"{fps:.1f}", help="æ¯ç§’è™•ç†å¹€æ•¸")

    # ç”Ÿæˆåœ–è¡¨
    st.subheader("ğŸ“Š å§¿å‹¢åˆ†æåœ–è¡¨")
    fig1, fig2, fig3, fig4, fig5 = generate_pose_analysis_plots(data_rows)

    # é¡¯ç¤ºåœ–è¡¨
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "å³è†è§’åº¦", "è†è“‹æ¯”è¼ƒ", "è»€å¹¹å‚¾æ–œ", "è…³è¸å‚ç›´è»Œè·¡", "è…³è¸2Dè»Œè·¡"
    ])

    with tab1:
        st.pyplot(fig1, width='stretch')
    with tab2:
        st.pyplot(fig2, width='stretch')
    with tab3:
        st.pyplot(fig3, width='stretch')
    with tab4:
        st.pyplot(fig4, width='stretch')
    with tab5:
        st.pyplot(fig5, width='stretch')

    # è¨ˆç®—å¹³å‡å€¼å’Œçµ±è¨ˆ
    st.subheader("ğŸ“ˆ å§¿å‹¢çµ±è¨ˆæ‘˜è¦")

    # æå–æ•¸æ“š
    right_knee_angles = [row["right_knee_angle"] for row in data_rows if not np.isnan(row["right_knee_angle"])]
    left_knee_angles = [row["left_knee_angle"] for row in data_rows if not np.isnan(row["left_knee_angle"])]
    trunk_lean_angles = [row["trunk_lean_deg"] for row in data_rows if not np.isnan(row["trunk_lean_deg"])]

    col1, col2, col3 = st.columns(3)

    with col1:
        st.write("### ğŸ¦µ è†è“‹è§’åº¦")
        if right_knee_angles:
            st.metric("å³è†å¹³å‡è§’åº¦", f"{np.mean(right_knee_angles):.1f}Â°")
            st.metric("å³è†æœ€å¤§è§’åº¦", f"{np.max(right_knee_angles):.1f}Â°")
            st.metric("å³è†æœ€å°è§’åº¦", f"{np.min(right_knee_angles):.1f}Â°")
        if left_knee_angles:
            st.metric("å·¦è†å¹³å‡è§’åº¦", f"{np.mean(left_knee_angles):.1f}Â°")

    with col2:
        st.write("### ğŸ«€ è»€å¹¹å‚¾æ–œ")
        if trunk_lean_angles:
            st.metric("å¹³å‡å‚¾æ–œè§’åº¦", f"{np.mean(trunk_lean_angles):.1f}Â°")
            st.metric("æœ€å¤§å‚¾æ–œè§’åº¦", f"{np.max(trunk_lean_angles):.1f}Â°")

    with col3:
        st.write("### ğŸ“Š æ•´é«”è©•åˆ†")
        # ç°¡å–®çš„è©•åˆ†é‚è¼¯
        symmetry_score = 100 - abs(np.mean(right_knee_angles) - np.mean(left_knee_angles)) if right_knee_angles and left_knee_angles else 0
        stability_score = 100 - np.std(trunk_lean_angles) if trunk_lean_angles else 0

        st.metric("å·¦å³å°ç¨±æ€§", f"{max(0, min(100, symmetry_score)):.1f}%")
        st.metric("å§¿å‹¢ç©©å®šæ€§", f"{max(0, min(100, stability_score)):.1f}%")

    # æä¾›æ•¸æ“šä¸‹è¼‰
    st.subheader("ğŸ’¾ ä¸‹è¼‰åˆ†ææ•¸æ“š")

    # å‰µå»ºCSVæ•¸æ“š
    csv_data = []
    for row in data_rows:
        csv_data.append({
            "å¹€æ•¸": row["frame"],
            "æ™‚é–“(ç§’)": row["time"],
            "å³è‚˜è§’åº¦": row["right_elbow_angle"],
            "å³è‚©è§’åº¦": row["right_shoulder_angle"],
            "å³è‡€è§’åº¦": row["right_hip_angle"],
            "å³è†è§’åº¦": row["right_knee_angle"],
            "å·¦è‡€è§’åº¦": row["left_hip_angle"],
            "å·¦è†è§’åº¦": row["left_knee_angle"],
            "è»€å¹¹å‚¾æ–œ": row["trunk_lean_deg"],
            "å³è¸X": row["right_ankle_x"],
            "å³è¸Y": row["right_ankle_y"],
            "å·¦è¸X": row["left_ankle_x"],
            "å·¦è¸Y": row["left_ankle_y"],
        })

    df = pd.DataFrame(csv_data)

    # CSVä¸‹è¼‰
    csv_buffer = df.to_csv(index=False, encoding='utf-8-sig')

    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰CSVæ•¸æ“š",
        data=csv_buffer,
        file_name=f"pose_analysis_{int(time.time())}.csv",
        mime="text/csv",
        key="download_csv"
    )

    # é¡¯ç¤ºæ•¸æ“šé è¦½
    st.subheader("ğŸ“‹ æ•¸æ“šé è¦½")
    st.dataframe(df.head(20), width='stretch')


def analyze_uploaded_video(video_file):
    """åˆ†æä¸Šå‚³çš„å½±ç‰‡"""
    st.success(f"âœ“ é–‹å§‹åˆ†æ {video_file.name}...")

    try:
        # ä¿å­˜ä¸Šå‚³çš„å½±ç‰‡åˆ°è‡¨æ™‚æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
            temp_file.write(video_file.read())
            temp_video_path = temp_file.name

        # åˆ†æå½±ç‰‡å§¿å‹¢
        st.subheader("ğŸ” æ­£åœ¨åˆ†æ...")
        data_rows, fps, width, height = analyze_video_pose(temp_video_path)

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        os.unlink(temp_video_path)

        if len(data_rows) == 0:
            st.error("âŒ æœªæª¢æ¸¬åˆ°ä»»ä½•å§¿å‹¢æ•¸æ“šï¼Œè«‹æª¢æŸ¥å½±ç‰‡æ˜¯å¦æ¸…æ™°ä¸”åŒ…å«äººé«”å‹•ä½œ")
            return

        st.success("âœ… åˆ†æå®Œæˆï¼")

        # é¡¯ç¤ºåˆ†æçµæœ
        display_analysis_results(data_rows)

    except Exception as e:
        st.error(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


def show():
    """å‹•ä½œåµæ¸¬é é¢"""
    st.header("ğŸ¥ AI å‹•ä½œåµæ¸¬")
    st.write("ä½¿ç”¨æ‚¨çš„æ”åƒé ­å¯¦æ™‚éŒ„è£½ä¸¦åˆ†æï¼Œæˆ–ä¸Šå‚³å½±ç‰‡é€²è¡Œåˆ†æ")
    
    st.divider()
    
    # åˆå§‹åŒ– session state
    if 'stop_recording' not in st.session_state:
        st.session_state.stop_recording = False
    
    # ==================== éŒ„è£½å’Œä¸Šå‚³é¸é … ====================
    tab_camera, tab_upload, tab_info, tab_tips = st.tabs(
        ["ğŸ“¹ æ”åƒé ­éŒ„è£½", "ğŸ“¤ ä¸Šå‚³å½±ç‰‡", "â„¹ï¸ é—œç¯€ç¯€é»ä»‹ç´¹", "ğŸ’¡ åµæ¸¬æç¤º"]
    )
    
    with tab_camera:
        st.write("### ğŸ“± å³æ™‚æ”åƒé ­éŒ„è£½å’Œåˆ†æ")
        st.warning("âš ï¸ æ³¨æ„ï¼šè«‹ç¢ºä¿æ”åƒé ­å·²æˆæ¬Šï¼Œå…‰ç·šå……è¶³ï¼Œç©¿è‘—è²¼èº«è¡£ç‰©")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("â–¶ï¸ é–‹å§‹éŒ„è£½", key="start_recording", type="primary", width='stretch'):
                st.session_state.stop_recording = False
                
                # å®šç¾©è¼¸å‡ºè·¯å¾‘
                output_video = "webcam_recording.mp4"
                
                # é–‹å§‹éŒ„è£½
                success, duration = record_from_webcam(output_video)
                
                if success and os.path.exists(output_video):
                    st.success(f"âœ… éŒ„è£½å®Œæˆï¼æ™‚é•·ï¼š{duration:.1f} ç§’")
                    
                    # é¡¯ç¤ºåˆ†æé¸é …
                    st.info("ç¾åœ¨é–‹å§‹åˆ†æéŒ„åˆ¶çš„å½±ç‰‡...")
                    data_rows, fps, width, height = analyze_video_pose(output_video)
                    
                    if len(data_rows) > 0:
                        st.success("âœ… åˆ†æå®Œæˆï¼")
                        st.divider()
                        display_analysis_results(data_rows)
                    else:
                        st.error("âŒ æœªåµæ¸¬åˆ°ä»»ä½•å§¿å‹¢æ•¸æ“š")
                else:
                    st.error("âŒ éŒ„è£½å¤±æ•—")

        with col2:
            if st.button("â¹ï¸ åœæ­¢éŒ„è£½", key="stop_recording_btn", width='stretch'):
                st.session_state.stop_recording = True
                st.info("â¸ï¸ æ­£åœ¨åœæ­¢éŒ„è£½...")

    with tab_upload:
        st.write("### ğŸ“¤ ä¸Šå‚³å½±ç‰‡é€²è¡Œåˆ†æ")
        uploaded_video = st.file_uploader(
            "é¸æ“‡å½±ç‰‡æª”æ¡ˆ (MP4, MOV, AVI, WebM)",
            type=["mp4", "mov", "avi", "webm"]
        )
        
        if uploaded_video:
            st.success(f"âœ“ å·²ä¸Šå‚³: {uploaded_video.name}")
            st.video(uploaded_video)

            # é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æª”æ¡ˆå¤§å°", f"{uploaded_video.size / (1024*1024):.1f} MB")
            with col2:
                st.metric("æª”æ¡ˆé¡å‹", uploaded_video.type)

            if st.button("ğŸ” åˆ†ææ­¤å½±ç‰‡", key="analyze_uploaded", type="primary", width='stretch'):
                analyze_uploaded_video(uploaded_video)
    
    with tab_info:
        st.write("### ğŸ¦´ é—œéµé—œç¯€ç¯€é»ä»‹ç´¹")
        
        st.write("""
        AI å‹•ä½œåˆ†æç³»çµ±æœƒç›£æ¸¬ä»¥ä¸‹ 17 å€‹é—œéµé—œç¯€é»ï¼Œä¾†åˆ¤æ–·æ‚¨çš„é‹å‹•å§¿å‹¢æ˜¯å¦æ­£ç¢ºï¼š
        """)
        
        # ä½¿ç”¨ tab ä¾†çµ„ç¹”ä¸åŒéƒ¨ä½çš„é—œç¯€
        joint_tab1, joint_tab2, joint_tab3, joint_tab4 = st.tabs(["ä¸Šè‚¢", "è»€å¹¹", "ä¸‹è‚¢", "å…¶ä»–"])
        
        with joint_tab1:
            st.write("**ä¸Šè‚¢é—œç¯€:**")
            joints_upper = [
                ("ğŸ‘ï¸ é¼»å­ (Nose)", "é¢éƒ¨ä¸­å¿ƒï¼Œç”¨æ–¼é ­éƒ¨æ–¹å‘åˆ¤æ–·"),
                ("ğŸ‘ï¸ å·¦çœ¼ (Left Eye)", "å·¦çœ¼ä½ç½®"),
                ("ğŸ‘ï¸ å³çœ¼ (Right Eye)", "å³çœ¼ä½ç½®"),
                ("ğŸ‘‚ å·¦è€³ (Left Ear)", "å·¦è€³ä½ç½®"),
                ("ğŸ‘‚ å³è€³ (Right Ear)", "å³è€³ä½ç½®"),
                ("ğŸ’ª å·¦è‚© (Left Shoulder)", "å·¦è‚©é—œç¯€ï¼Œæ±ºå®šä¸Šè‡‚ä½ç½®"),
                ("ğŸ’ª å³è‚© (Right Shoulder)", "å³è‚©é—œç¯€"),
                ("ğŸ¤š å·¦è‚˜ (Left Elbow)", "å·¦è‚˜é—œç¯€ï¼Œç›£æ¸¬æ‰‹è‡‚å½æ›²ç¨‹åº¦"),
                ("ğŸ¤š å³è‚˜ (Right Elbow)", "å³è‚˜é—œç¯€"),
                ("âœ‹ å·¦è…• (Left Wrist)", "å·¦æ‰‹è…•ï¼Œç›£æ¸¬æ‰‹è‡‚å»¶ä¼¸"),
                ("âœ‹ å³è…• (Right Wrist)", "å³æ‰‹è…•"),
            ]
            for joint, desc in joints_upper:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab2:
            st.write("**è»€å¹¹é—œç¯€:**")
            joints_torso = [
                ("ğŸ«€ å·¦é«– (Left Hip)", "å·¦é«–é—œç¯€ï¼Œå½±éŸ¿èº«é«”å‚¾æ–œ"),
                ("ğŸ«€ å³é«– (Right Hip)", "å³é«–é—œç¯€"),
            ]
            for joint, desc in joints_torso:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab3:
            st.write("**ä¸‹è‚¢é—œç¯€:**")
            joints_lower = [
                ("ğŸ¦µ å·¦è† (Left Knee)", "å·¦è†é—œç¯€ï¼Œæ·±è¹²æ™‚çš„é—œéµä½ç½®"),
                ("ğŸ¦µ å³è† (Right Knee)", "å³è†é—œç¯€"),
                ("ğŸ¦¶ å·¦è¸ (Left Ankle)", "å·¦è¸é—œç¯€ï¼Œå¹³è¡¡å’Œç©©å®šæ€§"),
                ("ğŸ¦¶ å³è¸ (Right Ankle)", "å³è¸é—œç¯€"),
            ]
            for joint, desc in joints_lower:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab4:
            st.write("**å…¶ä»–åƒæ•¸:**")
            st.write("""
            - **å°ç¨±æ€§ (Symmetry)**: å·¦å³å…©å´èº«é«”æ˜¯å¦å°ç¨±
            - **ç©©å®šæ€§ (Stability)**: èº«é«”é‡å¿ƒæ˜¯å¦ç©©å®š
            - **è§’åº¦ (Angles)**: å„é—œç¯€çš„å½æ›²è§’åº¦
            - **é€Ÿåº¦ (Velocity)**: å‹•ä½œåŸ·è¡Œé€Ÿåº¦æ˜¯å¦éå¿«/éæ…¢
            """)
    
    with tab_tips:
        st.write("### ğŸ’¡ æœ€ä½³å¯¦è¸")
        
        tips = [
            ("ğŸ“ ç«™ä½æ¸…æ™°", "è«‹ç«™åœ¨æ”åƒé ­å‰ 1-2 ç±³ï¼Œç¢ºä¿å…¨èº«éƒ½åœ¨é¡é ­ç¯„åœå…§"),
            ("ğŸ’¡ å…‰ç·šå……è¶³", "é¿å…é€†å…‰ï¼Œç¢ºä¿è¦–é »ç•«é¢æ¸…æ™°æ˜äº®"),
            ("ğŸ‘• ç©¿è‘—åˆé©", "ç©¿è‘—è²¼èº«è¡£ç‰©ï¼Œä½¿ AI èƒ½æ¸…æ¥šè­˜åˆ¥é—œç¯€é»"),
            ("ğŸ“¹ è§’åº¦é©ç•¶", "æœ€ä½³è§’åº¦æ˜¯æ­£é¢æˆ–å´é¢ 90 åº¦æ‹æ”"),
            ("â±ï¸ å®Œæ•´å‹•ä½œ", "éŒ„è£½å®Œæ•´çš„ä¸€å€‹å‹•ä½œå‘¨æœŸï¼ˆå¦‚ä¸€æ¬¡æ·±è¹²ï¼‰"),
            ("ğŸ¯ ä¸€å€‹å‹•ä½œ", "ä¸€æ¬¡éŒ„è£½åªåˆ†æä¸€ç¨®å‹•ä½œï¼ˆè·‘æ­¥ã€æ·±è¹²ç­‰ï¼‰"),
        ]
        
        col1, col2, col3 = st.columns(3)
        cols = [col1, col2, col3]
        
        for idx, (tip_title, tip_desc) in enumerate(tips):
            with cols[idx % 3]:
                with st.container(border=True):
                    st.write(f"**{tip_title}**")
                    st.write(tip_desc)
        
        st.divider()
        
        # ==================== æ”¯æ´çš„å‹•ä½œ ====================
        st.write("### ğŸ‹ï¸ ç›®å‰æ”¯æ´çš„å‹•ä½œåˆ†æ")
        
        supported_exercises = [
            ("ğŸƒ è·‘æ­¥ (Running)", "åˆ†ææ­¥å¹…ã€è…¿éƒ¨æ“¡èµ·ã€è‘—åœ°æ–¹å¼"),
            ("â¬‡ï¸ æ·±è¹² (Squat)", "åˆ†æè†è“‹è§’åº¦ã€èº«é«”å‚¾æ–œã€å°ç¨±æ€§"),
            ("ğŸ’ª ä¿¯å§æ’‘ (Push-up)", "åˆ†ææ‰‹è‡‚å½æ›²ã€èº«é«”å¹³ç›´åº¦ã€ä¸‹é™é«˜åº¦"),
            ("ğŸ§˜ ç‘œä¼½å§¿æ…‹ (Yoga)", "åˆ†æèº«é«”å°é½ã€å¹³è¡¡ã€éˆæ´»æ€§"),
            ("ğŸ¤¸ å¼“ç®­æ­¥ (Lunge)", "åˆ†æè†è“‹ä½ç½®ã€æ­¥å¹…ã€èº«é«”ç©©å®š"),
            ("ğŸ‹ï¸ èˆ‰é‡ (Lifting)", "åˆ†æè»€å¹¹å§¿æ…‹ã€æ‰‹è‡‚è·¯å¾‘ã€é‡å¿ƒ"),
        ]
        
        for exercise, description in supported_exercises:
            st.write(f"- **{exercise}**: {description}")

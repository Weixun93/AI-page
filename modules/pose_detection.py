import streamlit as st
import tempfile
import os
import cv2
import mediapipe as mp
import numpy as np
from collections import deque
import csv
import matplotlib.pyplot as plt
import pandas as pd
import time
import subprocess
import platform
import logging
import google.generativeai as genai

# æŠ‘åˆ¶ TensorFlow å’Œ MediaPipe çš„æ—¥èªŒ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('mediapipe').setLevel(logging.ERROR)

# Gemini API é…ç½®
GEMINI_API_KEY = "AIzaSyCn39H-Un3qYg5QRGWjxMjXqF1uNa1t7Dc"
genai.configure(api_key=GEMINI_API_KEY)


def calculate_angle(a, b, c):
    """
    è¨ˆç®—ä¸‰é»æ‰€å½¢æˆçš„å¤¾è§’ï¼Œb ç‚ºä¸­å¿ƒé»
    a, b, c: (x, y)
    """
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba = a - b
    bc = c - b
    denom = (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)
    if denom == 0:
        return np.nan
    cosine = np.dot(ba, bc) / denom
    return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))


def calculate_trunk_lean(shoulder, hip):
    """
    è»€å¹¹å‰å‚¾è§’ï¼šHip -> Shoulder èˆ‡ã€Œå‚ç›´å‘ä¸Šã€çš„å¤¾è§’
    å½±åƒåº§æ¨™ y è»¸å‘ä¸‹ç‚ºæ­£ï¼Œæ‰€ä»¥å‚ç›´å‘ä¸Šæ˜¯ (0, -1)
    """
    shoulder = np.array(shoulder)
    hip = np.array(hip)
    v = shoulder - hip           # hip -> shoulder
    vertical = np.array([0, -1.0])
    denom = (np.linalg.norm(v) * np.linalg.norm(vertical) + 1e-8)
    if denom == 0:
        return np.nan
    cosine = np.dot(v, vertical) / denom
    angle = np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))
    return angle


def record_from_webcam(output_video_path):
    """
    å¾æœ¬åœ°æ”åƒé ­éŒ„åˆ¶è¦–é »ï¼Œå³æ™‚é¡¯ç¤ºç¯€é»
    è¿”å›: (éŒ„åˆ¶æˆåŠŸèˆ‡å¦, éŒ„åˆ¶æ™‚é•·ç§’æ•¸)
    """
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    pose_style = mp.solutions.drawing_styles.get_default_pose_landmarks_style()
    connections = mp_pose.POSE_CONNECTIONS

    # åˆªé™¤èˆŠçš„å½±ç‰‡æª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if os.path.exists(output_video_path):
        try:
            os.remove(output_video_path)
        except Exception as e:
            st.warning(f"ç„¡æ³•åˆªé™¤èˆŠå½±ç‰‡æ–‡ä»¶: {e}")

    # æ‰“é–‹æœ¬åœ°æ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        st.error("âŒ ç„¡æ³•é–‹å•Ÿæ”åƒé ­ï¼Œè«‹æª¢æŸ¥æ”åƒé ­æ˜¯å¦å·²é€£æ¥")
        return False, 0

    # è¨­ç½®æ”åƒé ­åˆ†è¾¨ç‡
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    input_fps = cap.get(cv2.CAP_PROP_FPS)
    if input_fps <= 0 or np.isnan(input_fps):
        input_fps = 30.0

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # å˜—è©¦ä¸åŒçš„ç·¨ç¢¼æ–¹å¼
    fourcc_options = ['mp4v', 'XVID', 'MJPG', 'H264']
    out = None

    for fourcc_code in fourcc_options:
        try:
            fourcc = cv2.VideoWriter_fourcc(*fourcc_code)
            out = cv2.VideoWriter(output_video_path, fourcc, input_fps, (width, height))
            if out.isOpened():
                st.info(f"âœ… ä½¿ç”¨ {fourcc_code} ç·¨ç¢¼æˆåŠŸ")
                break
        except Exception as e:
            st.warning(f"ç·¨ç¢¼ {fourcc_code} å¤±æ•—: {e}")
            continue

    if out is None or not out.isOpened():
        st.error("âŒ ç„¡æ³•åˆå§‹åŒ–å½±ç‰‡å¯«å…¥å™¨ï¼Œè«‹æª¢æŸ¥ç³»çµ±æ˜¯å¦å®‰è£äº†é©ç•¶çš„ç·¨ç¢¼å™¨")
        cap.release()
        return False, 0

    st.info("ğŸ“¹ æ”åƒé ­å·²å•Ÿå‹•ï¼")
    frame_placeholder = st.empty()
    timer_placeholder = st.empty()
    frame_count = 0
    start_time = time.time()

    try:
        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    st.warning("ç„¡æ³•è®€å–æ”åƒé ­å¹€")
                    break

                # é¡åƒç¿»è½‰ä¾¿æ–¼è‡ªæ‹
                frame = cv2.flip(frame, 1)

                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb)

                if results.pose_landmarks:
                    # ç¹ªè£½éª¨æ¶å’Œç¯€é»
                    mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, connections,
                        landmark_drawing_spec=pose_style
                    )

                # æ·»åŠ ç‹€æ…‹æ–‡å­—
                cv2.putText(
                    frame, f"Recording... Frame: {frame_count}", (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2
                )

                # å¯«å…¥è¼¸å‡ºå½±ç‰‡
                if out.isOpened():
                    out.write(frame)
                else:
                    st.error("å½±ç‰‡å¯«å…¥å™¨å·²é—œé–‰")
                    break

                # è½‰æ›ç‚º RGB ä»¥åœ¨ Streamlit ä¸­é¡¯ç¤º
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(frame_rgb, width='stretch')

                # æ›´æ–°è¨ˆæ™‚å™¨
                elapsed_time = time.time() - start_time
                timer_placeholder.metric("â±ï¸ éŒ„è£½æ™‚é•·", f"{elapsed_time:.1f} ç§’")

                # æª¢æŸ¥åœæ­¢æ¨™èªŒ
                if st.session_state.get('stop_recording', False):
                    break

                frame_count += 1

                # é™åˆ¶éŒ„è£½æ™‚é–“ï¼ˆæœ€å¤š60ç§’ï¼‰
                if elapsed_time > 60:
                    st.warning("éŒ„è£½æ™‚é–“éé•·ï¼Œå·²è‡ªå‹•åœæ­¢")
                    break

    except Exception as e:
        st.error(f"éŒ„è£½éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False, 0

    finally:
        cap.release()
        if out is not None:
            out.release()
        cv2.destroyAllWindows()

    elapsed_time = time.time() - start_time

    # æª¢æŸ¥å½±ç‰‡æ˜¯å¦æˆåŠŸä¿å­˜
    if os.path.exists(output_video_path):
        file_size = os.path.getsize(output_video_path)
        if file_size > 1000:  # è‡³å°‘1KB
            st.success(f"âœ… å½±ç‰‡ä¿å­˜æˆåŠŸï¼å¤§å°: {file_size} bytes, å¹€æ•¸: {frame_count}")
            return True, elapsed_time
        else:
            st.error(f"âŒ å½±ç‰‡æ–‡ä»¶éå° ({file_size} bytes)ï¼Œå¯èƒ½ä¿å­˜å¤±æ•—")
            return False, 0
    else:
        st.error("âŒ å½±ç‰‡æ–‡ä»¶æœªå‰µå»º")
        return False, 0


def analyze_video_pose(video_path):
    """
    åˆ†æå·²éŒ„åˆ¶çš„è¦–é »ä¸­çš„å§¿å‹¢ï¼Œè¿”å›åˆ†ææ•¸æ“š
    """
    mp_pose = mp.solutions.pose
    smooth_buffer_size = 5
    elbow_R_buffer = deque(maxlen=smooth_buffer_size)
    wrist_R_buffer = deque(maxlen=smooth_buffer_size)

    # æª¢æŸ¥å½±ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        raise ValueError(f"å½±ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

    # æª¢æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(video_path)
    if file_size < 1000:  # å°æ–¼1KB
        raise ValueError(f"å½±ç‰‡æ–‡ä»¶éå° ({file_size} bytes)ï¼Œå¯èƒ½ä¿å­˜å¤±æ•—")

    st.info(f"æ­£åœ¨åˆ†æå½±ç‰‡: {video_path} (å¤§å°: {file_size} bytes)")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        # å˜—è©¦ä½¿ç”¨ä¸åŒçš„å¾Œç«¯
        cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)
        if not cap.isOpened():
            cap = cv2.VideoCapture(video_path, cv2.CAP_ANY)
            if not cap.isOpened():
                raise ValueError(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}ã€‚è«‹æª¢æŸ¥å½±ç‰‡æ ¼å¼å’Œç·¨ç¢¼ã€‚")

    # å–å¾—å½±ç‰‡è³‡è¨Š
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    input_fps = cap.get(cv2.CAP_PROP_FPS)
    if input_fps <= 0 or np.isnan(input_fps):
        input_fps = 30.0

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    st.info(f"å½±ç‰‡è³‡è¨Š: {width}x{height}, {total_frames}å¹€, {input_fps:.1f} FPS")

    data_rows = []
    frame_idx = 0

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        with mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb)

                if results.pose_landmarks:
                    h, w, _ = frame.shape
                    lm = results.pose_landmarks.landmark

                    def get_xy(name):
                        p = lm[mp_pose.PoseLandmark[name].value]
                        return np.array([p.x * w, p.y * h])

                    # å³å´é—œç¯€åº§æ¨™
                    shoulder_R = get_xy("RIGHT_SHOULDER")
                    elbow_R = get_xy("RIGHT_ELBOW")
                    wrist_R = get_xy("RIGHT_WRIST")
                    hip_R = get_xy("RIGHT_HIP")
                    knee_R = get_xy("RIGHT_KNEE")
                    ankle_R = get_xy("RIGHT_ANKLE")

                    # å·¦å´é—œç¯€åº§æ¨™
                    shoulder_L = get_xy("LEFT_SHOULDER")
                    hip_L = get_xy("LEFT_HIP")
                    knee_L = get_xy("LEFT_KNEE")
                    ankle_L = get_xy("LEFT_ANKLE")

                    # å¹³æ»‘åŒ–å³æ‰‹ç¯€é»
                    elbow_R_buffer.append(elbow_R)
                    wrist_R_buffer.append(wrist_R)

                    if len(elbow_R_buffer) == smooth_buffer_size:
                        elbow_R = np.mean(elbow_R_buffer, axis=0)
                        wrist_R = np.mean(wrist_R_buffer, axis=0)

                    # è§’åº¦è¨ˆç®—
                    right_elbow_angle = calculate_angle(shoulder_R, elbow_R, wrist_R)
                    right_shoulder_angle = calculate_angle(elbow_R, shoulder_R, hip_R)
                    right_hip_angle = calculate_angle(shoulder_R, hip_R, knee_R)
                    right_knee_angle = calculate_angle(hip_R, knee_R, ankle_R)

                    left_hip_angle = calculate_angle(shoulder_L, hip_L, knee_L)
                    left_knee_angle = calculate_angle(hip_L, knee_L, ankle_L)

                    # è»€å¹¹å‰å‚¾è§’
                    mid_shoulder = (
                        (shoulder_R[0] + shoulder_L[0]) / 2,
                        (shoulder_R[1] + shoulder_L[1]) / 2
                    )
                    mid_hip = (
                        (hip_R[0] + hip_L[0]) / 2,
                        (hip_R[1] + hip_L[1]) / 2
                    )
                    trunk_lean_deg = calculate_trunk_lean(mid_shoulder, mid_hip)

                    # è¨˜éŒ„æ•¸æ“š
                    time_sec = frame_idx / input_fps
                    data_rows.append({
                        "frame": frame_idx,
                        "time": time_sec,
                        "right_elbow_angle": right_elbow_angle,
                        "right_shoulder_angle": right_shoulder_angle,
                        "right_hip_angle": right_hip_angle,
                        "right_knee_angle": right_knee_angle,
                        "left_hip_angle": left_hip_angle,
                        "left_knee_angle": left_knee_angle,
                        "trunk_lean_deg": trunk_lean_deg,
                        "right_ankle_x": float(ankle_R[0]),
                        "right_ankle_y": float(ankle_R[1]),
                        "left_ankle_x": float(ankle_L[0]),
                        "left_ankle_y": float(ankle_L[1]),
                    })

                # æ›´æ–°é€²åº¦æ¢
                if total_frames > 0:
                    progress = min(frame_idx / total_frames, 1.0)
                    progress_bar.progress(progress)
                    status_text.text(f"åˆ†æä¸­... {frame_idx}/{total_frames} å¹€")

                frame_idx += 1

    finally:
        cap.release()
        progress_bar.empty()
        status_text.empty()

    st.success(f"åˆ†æå®Œæˆï¼å…±è™•ç† {len(data_rows)} å¹€æ•¸æ“š")
    return data_rows, input_fps, width, height


def generate_pose_analysis_plots(data_rows):
    """
    ç”Ÿæˆå§¿å‹¢åˆ†æåœ–è¡¨
    """
    if len(data_rows) == 0:
        return None, None, None, None, None

    times = [row["time"] for row in data_rows]

    # 1. å³è†è§’åº¦éš¨æ™‚é–“è®ŠåŒ–
    right_knee_angles = [row["right_knee_angle"] for row in data_rows]
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    ax1.plot(times, right_knee_angles, linewidth=2, color='#1f77b4')
    ax1.set_xlabel("Time (s)", fontsize=12)
    ax1.set_ylabel("Right Knee Angle (deg)", fontsize=12)
    ax1.set_title("Right Knee Angle over Time", fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    plt.tight_layout()

    # 2. å·¦å³è†è§’åº¦æ¯”è¼ƒ
    left_knee_angles = [row["left_knee_angle"] for row in data_rows]
    fig2, ax2 = plt.subplots(figsize=(10, 6))
    ax2.plot(times, right_knee_angles, label="Right Knee", linewidth=2, color='#ff7f0e')
    ax2.plot(times, left_knee_angles, label="Left Knee", linewidth=2, color='#2ca02c')
    ax2.set_xlabel("Time (s)", fontsize=12)
    ax2.set_ylabel("Knee Angle (deg)", fontsize=12)
    ax2.set_title("Left vs Right Knee Angle over Time", fontsize=14, fontweight='bold')
    ax2.legend(fontsize=11)
    ax2.grid(True, alpha=0.3)
    plt.tight_layout()

    # 3. è»€å¹¹å‰å‚¾è§’åº¦
    trunk_lean = [row["trunk_lean_deg"] for row in data_rows]
    fig3, ax3 = plt.subplots(figsize=(10, 6))
    ax3.plot(times, trunk_lean, linewidth=2, color='#d62728')
    ax3.set_xlabel("Time (s)", fontsize=12)
    ax3.set_ylabel("Trunk Lean (deg)", fontsize=12)
    ax3.set_title("Trunk Lean Angle over Time", fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    plt.tight_layout()

    # 4. å³è…³è¸å‚ç›´ä½ç§»
    right_ankle_y = [row["right_ankle_y"] for row in data_rows]
    fig4, ax4 = plt.subplots(figsize=(10, 6))
    ax4.plot(times, right_ankle_y, linewidth=2, color='#9467bd')
    ax4.set_xlabel("Time (s)", fontsize=12)
    ax4.set_ylabel("Right Ankle Y (pixel)", fontsize=12)
    ax4.set_title("Right Ankle Vertical Trajectory", fontsize=14, fontweight='bold')
    ax4.invert_yaxis()
    ax4.grid(True, alpha=0.3)
    plt.tight_layout()

    # 5. å³è…³è¸åœ¨ç•«é¢ä¸­çš„ 2D è·¯å¾‘
    right_ankle_x = [row["right_ankle_x"] for row in data_rows]
    fig5, ax5 = plt.subplots(figsize=(10, 6))
    ax5.plot(right_ankle_x, right_ankle_y, linewidth=2, color='#8c564b')
    ax5.set_xlabel("Right Ankle X (pixel)", fontsize=12)
    ax5.set_ylabel("Right Ankle Y (pixel)", fontsize=12)
    ax5.set_title("Right Ankle 2D Trajectory", fontsize=14, fontweight='bold')
    ax5.invert_yaxis()
    ax5.grid(True, alpha=0.3)
    plt.tight_layout()

    return fig1, fig2, fig3, fig4, fig5


def display_analysis_results(data_rows):
    """
    é¡¯ç¤ºå§¿å‹¢åˆ†æçµæœï¼ŒåŒ…æ‹¬åœ–è¡¨ã€çµ±è¨ˆå’Œæ•¸æ“šä¸‹è¼‰
    """
    if len(data_rows) == 0:
        st.warning("æ²’æœ‰åˆ†ææ•¸æ“šå¯é¡¯ç¤º")
        return

    # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("ç¸½å¹€æ•¸", f"{len(data_rows)}", help="å·²åˆ†æçš„å½±ç‰‡å¹€æ•¸")
    with col2:
        duration = data_rows[-1]["time"] if data_rows else 0
        st.metric("åˆ†ææ™‚é–“", f"{duration:.1f}ç§’", help="åˆ†æçš„æŒçºŒæ™‚é–“")
    with col3:
        fps = len(data_rows) / duration if duration > 0 else 0
        st.metric("å¹³å‡ FPS", f"{fps:.1f}", help="æ¯ç§’è™•ç†å¹€æ•¸")

    # ç”Ÿæˆåœ–è¡¨
    st.subheader("ğŸ“Š å§¿å‹¢åˆ†æåœ–è¡¨")
    fig1, fig2, fig3, fig4, fig5 = generate_pose_analysis_plots(data_rows)

    # é¡¯ç¤ºåœ–è¡¨
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "å³è†è§’åº¦", "è†è“‹æ¯”è¼ƒ", "è»€å¹¹å‚¾æ–œ", "è…³è¸å‚ç›´è»Œè·¡", "è…³è¸2Dè»Œè·¡"
    ])

    with tab1:
        st.pyplot(fig1, width='stretch')
    with tab2:
        st.pyplot(fig2, width='stretch')
    with tab3:
        st.pyplot(fig3, width='stretch')
    with tab4:
        st.pyplot(fig4, width='stretch')
    with tab5:
        st.pyplot(fig5, width='stretch')

    # è¨ˆç®—å¹³å‡å€¼å’Œçµ±è¨ˆ
    st.subheader("ğŸ“ˆ å§¿å‹¢çµ±è¨ˆæ‘˜è¦")

    # æå–æ•¸æ“š
    right_knee_angles = [row["right_knee_angle"] for row in data_rows if not np.isnan(row["right_knee_angle"])]
    left_knee_angles = [row["left_knee_angle"] for row in data_rows if not np.isnan(row["left_knee_angle"])]
    trunk_lean_angles = [row["trunk_lean_deg"] for row in data_rows if not np.isnan(row["trunk_lean_deg"])]

    col1, col2, col3 = st.columns(3)

    with col1:
        st.write("### ğŸ¦µ è†è“‹è§’åº¦")
        if right_knee_angles:
            st.metric("å³è†å¹³å‡è§’åº¦", f"{np.mean(right_knee_angles):.1f}Â°")
            st.metric("å³è†æœ€å¤§è§’åº¦", f"{np.max(right_knee_angles):.1f}Â°")
            st.metric("å³è†æœ€å°è§’åº¦", f"{np.min(right_knee_angles):.1f}Â°")
        if left_knee_angles:
            st.metric("å·¦è†å¹³å‡è§’åº¦", f"{np.mean(left_knee_angles):.1f}Â°")

    with col2:
        st.write("### ğŸ«€ è»€å¹¹å‚¾æ–œ")
        if trunk_lean_angles:
            st.metric("å¹³å‡å‚¾æ–œè§’åº¦", f"{np.mean(trunk_lean_angles):.1f}Â°")
            st.metric("æœ€å¤§å‚¾æ–œè§’åº¦", f"{np.max(trunk_lean_angles):.1f}Â°")

    with col3:
        st.write("### ğŸ“Š æ•´é«”è©•åˆ†")
        # ç°¡å–®çš„è©•åˆ†é‚è¼¯
        symmetry_score = 100 - abs(np.mean(right_knee_angles) - np.mean(left_knee_angles)) if right_knee_angles and left_knee_angles else 0
        stability_score = 100 - np.std(trunk_lean_angles) if trunk_lean_angles else 0

        st.metric("å·¦å³å°ç¨±æ€§", f"{max(0, min(100, symmetry_score)):.1f}%")
        st.metric("å§¿å‹¢ç©©å®šæ€§", f"{max(0, min(100, stability_score)):.1f}%")

    # AI æ™ºèƒ½å»ºè­°
    st.subheader("ğŸ¤– AI æ™ºèƒ½å»ºè­°")

    with st.spinner("æ­£åœ¨ç”Ÿæˆå€‹äººåŒ–å»ºè­°..."):
        ai_recommendations = analyze_pose_with_gemini(data_rows)

    if ai_recommendations:
        # å°‡å»ºè­°åˆ†æ®µé¡¯ç¤º
        sections = ai_recommendations.split('\n\n')

        for section in sections:
            if section.strip():
                lines = section.strip().split('\n')
                content_lines = []

                # æª¢æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åŒ…å«æ¨™é¡Œ
                first_line = lines[0].strip() if lines else ""
                is_title_line = False

                if 'æ•´é«”å§¿å‹¢è©•ä¼°' in first_line or (first_line.startswith('1.') and 'è©•ä¼°' in first_line):
                    with st.container(border=True):
                        st.write("**ğŸ“‹ æ•´é«”å§¿å‹¢è©•ä¼°**")
                        content_lines = lines[1:] if len(lines) > 1 else []
                        is_title_line = True
                elif 'å…·é«”çš„æ”¹é€²å»ºè­°' in first_line or (first_line.startswith('2.') and 'æ”¹é€²å»ºè­°' in first_line):
                    with st.container(border=True):
                        st.write("**ğŸ’¡ å…·é«”æ”¹é€²å»ºè­°**")
                        content_lines = lines[1:] if len(lines) > 1 else []
                        is_title_line = True
                elif 'é‹å‹•å»ºè­°' in first_line or (first_line.startswith('3.') and 'é‹å‹•å»ºè­°' in first_line):
                    with st.container(border=True):
                        st.write("**ğŸ‹ï¸ é‹å‹•å»ºè­°**")
                        content_lines = lines[1:] if len(lines) > 1 else []
                        is_title_line = True
                elif 'é é˜²å‚·å®³æç¤º' in first_line or (first_line.startswith('4.') and 'é é˜²å‚·å®³' in first_line):
                    with st.container(border=True):
                        st.write("**âš ï¸ é é˜²å‚·å®³æç¤º**")
                        content_lines = lines[1:] if len(lines) > 1 else []
                        is_title_line = True

                # å¦‚æœæ²’æœ‰è­˜åˆ¥åˆ°æ¨™é¡Œè¡Œï¼Œæ•´æ®µé¡¯ç¤º
                if not is_title_line:
                    st.write(section.strip())
                else:
                    # é¡¯ç¤ºå…§å®¹éƒ¨åˆ†
                    content = '\n'.join(content_lines).strip()
                    if content:
                        st.write(content)
    else:
        st.warning("ç„¡æ³•ç”Ÿæˆ AI å»ºè­°ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥")

    # æä¾›æ•¸æ“šä¸‹è¼‰
    st.subheader("ğŸ’¾ ä¸‹è¼‰åˆ†ææ•¸æ“š")

    # å‰µå»ºCSVæ•¸æ“š
    csv_data = []
    for row in data_rows:
        csv_data.append({
            "å¹€æ•¸": row["frame"],
            "æ™‚é–“(ç§’)": row["time"],
            "å³è‚˜è§’åº¦": row["right_elbow_angle"],
            "å³è‚©è§’åº¦": row["right_shoulder_angle"],
            "å³è‡€è§’åº¦": row["right_hip_angle"],
            "å³è†è§’åº¦": row["right_knee_angle"],
            "å·¦è‡€è§’åº¦": row["left_hip_angle"],
            "å·¦è†è§’åº¦": row["left_knee_angle"],
            "è»€å¹¹å‚¾æ–œ": row["trunk_lean_deg"],
            "å³è¸X": row["right_ankle_x"],
            "å³è¸Y": row["right_ankle_y"],
            "å·¦è¸X": row["left_ankle_x"],
            "å·¦è¸Y": row["left_ankle_y"],
        })

    df = pd.DataFrame(csv_data)

    # CSVä¸‹è¼‰
    csv_buffer = df.to_csv(index=False, encoding='utf-8-sig')

    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰CSVæ•¸æ“š",
        data=csv_buffer,
        file_name=f"pose_analysis_{int(time.time())}.csv",
        mime="text/csv",
        key="download_csv"
    )

    # é¡¯ç¤ºæ•¸æ“šé è¦½
    st.subheader("ğŸ“‹ æ•¸æ“šé è¦½")
    st.dataframe(df.head(20), width='stretch')


def analyze_pose_with_gemini(data_rows):
    """
    ä½¿ç”¨ Gemini API åˆ†æå§¿å‹¢æ•¸æ“šä¸¦ç”Ÿæˆ AI å»ºè­°
    """
    try:
        # æº–å‚™æ•¸æ“šæ‘˜è¦
        if len(data_rows) == 0:
            return "æ²’æœ‰è¶³å¤ çš„æ•¸æ“šé€²è¡Œåˆ†æ"

        # è¨ˆç®—é—œéµçµ±è¨ˆæ•¸æ“š
        right_knee_angles = [row["right_knee_angle"] for row in data_rows if not np.isnan(row["right_knee_angle"])]
        left_knee_angles = [row["left_knee_angle"] for row in data_rows if not np.isnan(row["left_knee_angle"])]
        trunk_lean_angles = [row["trunk_lean_deg"] for row in data_rows if not np.isnan(row["trunk_lean_deg"])]

        # åŸºæœ¬çµ±è¨ˆ
        stats_summary = {
            "total_frames": len(data_rows),
            "duration": data_rows[-1]["time"] if data_rows else 0,
            "right_knee_avg": np.mean(right_knee_angles) if right_knee_angles else None,
            "left_knee_avg": np.mean(left_knee_angles) if left_knee_angles else None,
            "trunk_lean_avg": np.mean(trunk_lean_angles) if trunk_lean_angles else None,
            "right_knee_min": np.min(right_knee_angles) if right_knee_angles else None,
            "right_knee_max": np.max(right_knee_angles) if right_knee_angles else None,
            "symmetry_score": 100 - abs(np.mean(right_knee_angles) - np.mean(left_knee_angles)) if right_knee_angles and left_knee_angles else None,
            "stability_score": 100 - np.std(trunk_lean_angles) if trunk_lean_angles else None
        }

        # å‰µå»ºåˆ†ææç¤º
        prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹å§¿å‹¢åˆ†ææ•¸æ“šï¼Œç‚ºç”¨æˆ¶æä¾›å°ˆæ¥­çš„é‹å‹•å»ºè­°å’Œå§¿å‹¢æ”¹é€²æŒ‡å°ï¼š

æ•¸æ“šçµ±è¨ˆï¼š
- ç¸½å¹€æ•¸: {stats_summary['total_frames']}
- åˆ†ææ™‚é•·: {stats_summary['duration']:.1f} ç§’
- å³è†å¹³å‡è§’åº¦: {stats_summary['right_knee_avg']:.1f}Â° (ç¯„åœ: {stats_summary['right_knee_min']:.1f}Â° - {stats_summary['right_knee_max']:.1f}Â°)
- å·¦è†å¹³å‡è§’åº¦: {stats_summary['left_knee_avg']:.1f}Â°
- è»€å¹¹å¹³å‡å‚¾æ–œ: {stats_summary['trunk_lean_avg']:.1f}Â°
- å·¦å³å°ç¨±æ€§åˆ†æ•¸: {stats_summary['symmetry_score']:.1f}/100
- å§¿å‹¢ç©©å®šæ€§åˆ†æ•¸: {stats_summary['stability_score']:.1f}/100

è«‹æä¾›ä»¥ä¸‹å…§å®¹ï¼š
1. æ•´é«”å§¿å‹¢è©•ä¼° (ç°¡æ½”ç¸½çµ)
2. å…·é«”çš„æ”¹é€²å»ºè­° (é‡å°è†è“‹è§’åº¦ã€è»€å¹¹å§¿å‹¢ç­‰)
3. é‹å‹•å»ºè­° (é©åˆçš„è¨“ç·´å‹•ä½œ)
4. é é˜²å‚·å®³æç¤º

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­ä¸”é¼“å‹µæ€§çš„èªæ°£ã€‚
"""

        # ä½¿ç”¨ Gemini API ç”Ÿæˆå»ºè­°
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content(prompt)

        return response.text.strip()

    except Exception as e:
        return f"AI åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"


def analyze_uploaded_video(video_file):
    """åˆ†æä¸Šå‚³çš„å½±ç‰‡"""
    st.success(f"âœ“ é–‹å§‹åˆ†æ {video_file.name}...")

    try:
        # ä¿å­˜ä¸Šå‚³çš„å½±ç‰‡åˆ°è‡¨æ™‚æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
            temp_file.write(video_file.read())
            temp_video_path = temp_file.name

        # åˆ†æå½±ç‰‡å§¿å‹¢
        st.subheader("ğŸ” æ­£åœ¨åˆ†æ...")
        data_rows, fps, width, height = analyze_video_pose(temp_video_path)

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        os.unlink(temp_video_path)

        if len(data_rows) == 0:
            st.error("âŒ æœªæª¢æ¸¬åˆ°ä»»ä½•å§¿å‹¢æ•¸æ“šï¼Œè«‹æª¢æŸ¥å½±ç‰‡æ˜¯å¦æ¸…æ™°ä¸”åŒ…å«äººé«”å‹•ä½œ")
            return

        st.success("âœ… åˆ†æå®Œæˆï¼")

        # é¡¯ç¤ºåˆ†æçµæœ
        display_analysis_results(data_rows)

    except Exception as e:
        st.error(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


def show():
    """å‹•ä½œåµæ¸¬é é¢"""
    st.header("ğŸ¥ AI å‹•ä½œåµæ¸¬")
    st.write("ä½¿ç”¨æ‚¨çš„æ”åƒé ­å¯¦æ™‚éŒ„è£½ä¸¦åˆ†æï¼Œæˆ–ä¸Šå‚³å½±ç‰‡é€²è¡Œåˆ†æ")
    
    st.divider()
    
    # åˆå§‹åŒ– session state
    if 'stop_recording' not in st.session_state:
        st.session_state.stop_recording = False
    if 'analysis_data' not in st.session_state:
        st.session_state.analysis_data = None
    if 'recording_complete' not in st.session_state:
        st.session_state.recording_complete = False
    if 'analyzing' not in st.session_state:
        st.session_state.analyzing = False
    if 'video_saved' not in st.session_state:
        st.session_state.video_saved = False
    
    # ==================== éŒ„è£½å’Œä¸Šå‚³é¸é … ====================
    tab_camera, tab_upload, tab_info, tab_tips = st.tabs(
        ["ğŸ“¹ æ”åƒé ­éŒ„è£½", "ğŸ“¤ ä¸Šå‚³å½±ç‰‡", "â„¹ï¸ é—œç¯€ç¯€é»ä»‹ç´¹", "ğŸ’¡ åµæ¸¬æç¤º"]
    )
    
    with tab_camera:
        st.write("### ğŸ“± å³æ™‚æ”åƒé ­éŒ„è£½å’Œåˆ†æ")
        st.warning("âš ï¸ æ³¨æ„ï¼šè«‹ç¢ºä¿æ”åƒé ­å·²æˆæ¬Šï¼Œå…‰ç·šå……è¶³ï¼Œç©¿è‘—è²¼èº«è¡£ç‰©")

        # ç‹€æ…‹é¡¯ç¤ºå€åŸŸ
        status_container = st.empty()
        
        # éŒ„è£½æ§åˆ¶æŒ‰éˆ•
        col1, col2 = st.columns(2)
        with col1:
            start_btn = st.button("â–¶ï¸ é–‹å§‹éŒ„è£½", key="start_recording", type="primary", width='stretch')
        with col2:
            stop_btn = st.button("â¹ï¸ åœæ­¢éŒ„è£½", key="stop_recording_btn", width='stretch')

        # å¦‚æœé»æ“Šé–‹å§‹éŒ„è£½
        if start_btn:
            # å¼·åˆ¶é‡ç½®æ‰€æœ‰ç‹€æ…‹ï¼Œç¢ºä¿æ¯æ¬¡é–‹å§‹éƒ½æ˜¯å…¨æ–°çš„éŒ„è£½
            st.session_state.stop_recording = False
            st.session_state.recording_complete = False
            st.session_state.analysis_data = None
            st.session_state.analyzing = False
            st.session_state.video_saved = False

            # åˆªé™¤èˆŠçš„å½±ç‰‡æ–‡ä»¶ï¼Œç¢ºä¿ä¸æœƒè®€å–åˆ°ä¹‹å‰çš„éŒ„è£½
            output_video = "webcam_recording.mp4"
            if os.path.exists(output_video):
                try:
                    os.remove(output_video)
                    st.info("ğŸ—‘ï¸ å·²æ¸…é™¤èˆŠçš„éŒ„è£½æ–‡ä»¶")
                except Exception as e:
                    st.warning(f"ç„¡æ³•åˆªé™¤èˆŠæ–‡ä»¶: {e}")

            # é–‹å§‹æ–°çš„éŒ„è£½
            success, duration = record_from_webcam(output_video)

            if success:
                st.session_state.video_saved = True
                st.session_state.recording_complete = True
                status_container.success(f"âœ… éŒ„è£½å®Œæˆï¼æ™‚é•·ï¼š{duration:.1f} ç§’")
            else:
                status_container.error("âŒ éŒ„è£½å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ”åƒé ­æ¬Šé™")

        # å¦‚æœé»æ“Šåœæ­¢éŒ„è£½
        if stop_btn:
            st.session_state.stop_recording = True
            status_container.info("ğŸ”„ æ­£åœ¨åœæ­¢éŒ„è£½...")
            # ä¸ç«‹å³é–‹å§‹åˆ†æï¼Œè®“ç”¨æˆ¶æ±ºå®šæ˜¯å¦é‡æ–°éŒ„è£½
            time.sleep(0.5)  # çµ¦ä¸€é»æ™‚é–“è®“éŒ„è£½å®Œå…¨åœæ­¢
            st.rerun()

        # å¦‚æœéŒ„è£½å·²å®Œæˆä¸”å½±ç‰‡å·²ä¿å­˜ï¼Œé¡¯ç¤ºåˆ†æé¸é …
        if st.session_state.recording_complete and st.session_state.video_saved and not st.session_state.analysis_data:
            status_container.success("âœ… éŒ„è£½å®Œæˆï¼æº–å‚™å¥½åˆ†æå—ï¼Ÿ")

            # æ·»åŠ åˆ†ææŒ‰éˆ•
            if st.button("ğŸ” åˆ†ææ­¤éŒ„è£½", key="analyze_recording", type="primary", width='stretch'):
                st.session_state.analyzing = True
                status_container.info("ğŸ”„ æ­£åœ¨åˆ†æéŒ„åˆ¶çš„å½±ç‰‡ï¼Œè«‹ç¨å€™...")

                output_video = "webcam_recording.mp4"
                data_rows, fps, width, height = analyze_video_pose(output_video)

                if len(data_rows) > 0:
                    st.session_state.analysis_data = data_rows
                    st.session_state.analyzing = False
                    status_container.success("âœ… åˆ†æå®Œæˆï¼")
                else:
                    st.session_state.analyzing = False
                    status_container.error("âŒ æœªåµæ¸¬åˆ°ä»»ä½•å§¿å‹¢æ•¸æ“š")

        # å¦‚æœæ­£åœ¨åˆ†æä¸­
        elif st.session_state.analyzing:
            status_container.info("ğŸ”„ æ­£åœ¨åˆ†æéŒ„åˆ¶çš„å½±ç‰‡ï¼Œè«‹ç¨å€™...")

        # å¦‚æœåˆ†æå®Œæˆä¸¦æœ‰æ•¸æ“šï¼Œé¡¯ç¤ºçµæœ
        if st.session_state.analysis_data:
            st.divider()
            st.header("ğŸ“Š å§¿å‹¢åˆ†æçµæœ")
            st.info("ğŸ‘‡ **åˆ†æçµæœå·²é¡¯ç¤ºåœ¨ä¸‹æ–¹** ğŸ‘‡")
            display_analysis_results(st.session_state.analysis_data)
            
            # æ·»åŠ é‡æ–°é–‹å§‹æŒ‰éˆ•
            if st.button("ğŸ”„ é‡æ–°éŒ„è£½", key="restart_recording", width='stretch'):
                # æ¸…é™¤èˆŠçš„å½±ç‰‡æ–‡ä»¶
                output_video = "webcam_recording.mp4"
                if os.path.exists(output_video):
                    try:
                        os.remove(output_video)
                    except Exception as e:
                        st.warning(f"ç„¡æ³•åˆªé™¤èˆŠæ–‡ä»¶: {e}")

                # é‡ç½®æ‰€æœ‰ç‹€æ…‹
                st.session_state.stop_recording = False
                st.session_state.recording_complete = False
                st.session_state.analysis_data = None
                st.session_state.analyzing = False
                st.session_state.video_saved = False
                status_container.empty()
                st.rerun()

    with tab_upload:
        st.write("### ğŸ“¤ ä¸Šå‚³å½±ç‰‡é€²è¡Œåˆ†æ")
        uploaded_video = st.file_uploader(
            "é¸æ“‡å½±ç‰‡æª”æ¡ˆ (MP4, MOV, AVI, WebM)",
            type=["mp4", "mov", "avi", "webm"]
        )
        
        if uploaded_video:
            st.success(f"âœ“ å·²ä¸Šå‚³: {uploaded_video.name}")
            st.video(uploaded_video)

            # é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æª”æ¡ˆå¤§å°", f"{uploaded_video.size / (1024*1024):.1f} MB")
            with col2:
                st.metric("æª”æ¡ˆé¡å‹", uploaded_video.type)

            if st.button("ğŸ” åˆ†ææ­¤å½±ç‰‡", key="analyze_uploaded", type="primary", width='stretch'):
                analyze_uploaded_video(uploaded_video)
    
    with tab_info:
        st.write("### ğŸ¦´ é—œéµé—œç¯€ç¯€é»ä»‹ç´¹")
        
        st.write("""
        AI å‹•ä½œåˆ†æç³»çµ±æœƒç›£æ¸¬ä»¥ä¸‹ 17 å€‹é—œéµé—œç¯€é»ï¼Œä¾†åˆ¤æ–·æ‚¨çš„é‹å‹•å§¿å‹¢æ˜¯å¦æ­£ç¢ºï¼š
        """)
        
        # ä½¿ç”¨ tab ä¾†çµ„ç¹”ä¸åŒéƒ¨ä½çš„é—œç¯€
        joint_tab1, joint_tab2, joint_tab3, joint_tab4 = st.tabs(["ä¸Šè‚¢", "è»€å¹¹", "ä¸‹è‚¢", "å…¶ä»–"])
        
        with joint_tab1:
            st.write("**ä¸Šè‚¢é—œç¯€:**")
            joints_upper = [
                ("ğŸ‘ï¸ é¼»å­ (Nose)", "é¢éƒ¨ä¸­å¿ƒï¼Œç”¨æ–¼é ­éƒ¨æ–¹å‘åˆ¤æ–·"),
                ("ğŸ‘ï¸ å·¦çœ¼ (Left Eye)", "å·¦çœ¼ä½ç½®"),
                ("ğŸ‘ï¸ å³çœ¼ (Right Eye)", "å³çœ¼ä½ç½®"),
                ("ğŸ‘‚ å·¦è€³ (Left Ear)", "å·¦è€³ä½ç½®"),
                ("ğŸ‘‚ å³è€³ (Right Ear)", "å³è€³ä½ç½®"),
                ("ğŸ’ª å·¦è‚© (Left Shoulder)", "å·¦è‚©é—œç¯€ï¼Œæ±ºå®šä¸Šè‡‚ä½ç½®"),
                ("ğŸ’ª å³è‚© (Right Shoulder)", "å³è‚©é—œç¯€"),
                ("ğŸ¤š å·¦è‚˜ (Left Elbow)", "å·¦è‚˜é—œç¯€ï¼Œç›£æ¸¬æ‰‹è‡‚å½æ›²ç¨‹åº¦"),
                ("ğŸ¤š å³è‚˜ (Right Elbow)", "å³è‚˜é—œç¯€"),
                ("âœ‹ å·¦è…• (Left Wrist)", "å·¦æ‰‹è…•ï¼Œç›£æ¸¬æ‰‹è‡‚å»¶ä¼¸"),
                ("âœ‹ å³è…• (Right Wrist)", "å³æ‰‹è…•"),
            ]
            for joint, desc in joints_upper:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab2:
            st.write("**è»€å¹¹é—œç¯€:**")
            joints_torso = [
                ("ğŸ«€ å·¦é«– (Left Hip)", "å·¦é«–é—œç¯€ï¼Œå½±éŸ¿èº«é«”å‚¾æ–œ"),
                ("ğŸ«€ å³é«– (Right Hip)", "å³é«–é—œç¯€"),
            ]
            for joint, desc in joints_torso:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab3:
            st.write("**ä¸‹è‚¢é—œç¯€:**")
            joints_lower = [
                ("ğŸ¦µ å·¦è† (Left Knee)", "å·¦è†é—œç¯€ï¼Œæ·±è¹²æ™‚çš„é—œéµä½ç½®"),
                ("ğŸ¦µ å³è† (Right Knee)", "å³è†é—œç¯€"),
                ("ğŸ¦¶ å·¦è¸ (Left Ankle)", "å·¦è¸é—œç¯€ï¼Œå¹³è¡¡å’Œç©©å®šæ€§"),
                ("ğŸ¦¶ å³è¸ (Right Ankle)", "å³è¸é—œç¯€"),
            ]
            for joint, desc in joints_lower:
                st.write(f"- {joint}: {desc}")
        
        with joint_tab4:
            st.write("**å…¶ä»–åƒæ•¸:**")
            st.write("""
            - **å°ç¨±æ€§ (Symmetry)**: å·¦å³å…©å´èº«é«”æ˜¯å¦å°ç¨±
            - **ç©©å®šæ€§ (Stability)**: èº«é«”é‡å¿ƒæ˜¯å¦ç©©å®š
            - **è§’åº¦ (Angles)**: å„é—œç¯€çš„å½æ›²è§’åº¦
            - **é€Ÿåº¦ (Velocity)**: å‹•ä½œåŸ·è¡Œé€Ÿåº¦æ˜¯å¦éå¿«/éæ…¢
            """)
    
    with tab_tips:
        st.write("### ğŸ’¡ æœ€ä½³å¯¦è¸")
        
        tips = [
            ("ğŸ“ ç«™ä½æ¸…æ™°", "è«‹ç«™åœ¨æ”åƒé ­å‰ 1-2 ç±³ï¼Œç¢ºä¿å…¨èº«éƒ½åœ¨é¡é ­ç¯„åœå…§"),
            ("ğŸ’¡ å…‰ç·šå……è¶³", "é¿å…é€†å…‰ï¼Œç¢ºä¿è¦–é »ç•«é¢æ¸…æ™°æ˜äº®"),
            ("ğŸ‘• ç©¿è‘—åˆé©", "ç©¿è‘—è²¼èº«è¡£ç‰©ï¼Œä½¿ AI èƒ½æ¸…æ¥šè­˜åˆ¥é—œç¯€é»"),
            ("ğŸ“¹ è§’åº¦é©ç•¶", "æœ€ä½³è§’åº¦æ˜¯æ­£é¢æˆ–å´é¢ 90 åº¦æ‹æ”"),
            ("â±ï¸ å®Œæ•´å‹•ä½œ", "éŒ„è£½å®Œæ•´çš„ä¸€å€‹å‹•ä½œå‘¨æœŸï¼ˆå¦‚ä¸€æ¬¡æ·±è¹²ï¼‰"),
            ("ğŸ¯ ä¸€å€‹å‹•ä½œ", "ä¸€æ¬¡éŒ„è£½åªåˆ†æä¸€ç¨®å‹•ä½œï¼ˆè·‘æ­¥ã€æ·±è¹²ç­‰ï¼‰"),
        ]
        
        col1, col2, col3 = st.columns(3)
        cols = [col1, col2, col3]
        
        for idx, (tip_title, tip_desc) in enumerate(tips):
            with cols[idx % 3]:
                with st.container(border=True):
                    st.write(f"**{tip_title}**")
                    st.write(tip_desc)
        
        st.divider()
        
        # ==================== æ”¯æ´çš„å‹•ä½œ ====================
        st.write("### ğŸ‹ï¸ ç›®å‰æ”¯æ´çš„å‹•ä½œåˆ†æ")
        
        supported_exercises = [
            ("ğŸƒ è·‘æ­¥ (Running)", "åˆ†ææ­¥å¹…ã€è…¿éƒ¨æ“¡èµ·ã€è‘—åœ°æ–¹å¼"),
            ("â¬‡ï¸ æ·±è¹² (Squat)", "åˆ†æè†è“‹è§’åº¦ã€èº«é«”å‚¾æ–œã€å°ç¨±æ€§"),
            ("ğŸ’ª ä¿¯å§æ’‘ (Push-up)", "åˆ†ææ‰‹è‡‚å½æ›²ã€èº«é«”å¹³ç›´åº¦ã€ä¸‹é™é«˜åº¦"),
            ("ğŸ§˜ ç‘œä¼½å§¿æ…‹ (Yoga)", "åˆ†æèº«é«”å°é½ã€å¹³è¡¡ã€éˆæ´»æ€§"),
            ("ğŸ¤¸ å¼“ç®­æ­¥ (Lunge)", "åˆ†æè†è“‹ä½ç½®ã€æ­¥å¹…ã€èº«é«”ç©©å®š"),
            ("ğŸ‹ï¸ èˆ‰é‡ (Lifting)", "åˆ†æè»€å¹¹å§¿æ…‹ã€æ‰‹è‡‚è·¯å¾‘ã€é‡å¿ƒ"),
        ]
        
        for exercise, description in supported_exercises:
            st.write(f"- **{exercise}**: {description}")
